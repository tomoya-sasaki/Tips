{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "* [here](https://null-byte.wonderhowto.com/how-to/download-all-pdfs-webpage-with-python-script-0163031/)\n",
    "* [here](https://stackoverflow.com/questions/7243750/download-file-from-web-in-python-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse as urllib\n",
    "import urllib3\n",
    "import os\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as urllibR\n",
    "from requests import get\n",
    "from time import sleep, time\n",
    "import re\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function to download (bypass using firefox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "def obtain_bs4soup(url, bypass):\n",
    "    try:\n",
    "        os.mkdir(download_path)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0\",\n",
    "    }\n",
    "    \n",
    "    ## Choose whether to bypass through firefox\n",
    "    if bypass == True:\n",
    "        request0 = urllibR.Request(url=url, headers=headers)\n",
    "        request = urllibR.urlopen(request0)\n",
    "    else:\n",
    "        request = urllibR.urlopen(url)\n",
    "        \n",
    "    soup = BeautifulSoup(request.read(), \"lxml\")\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "def download(url, file_name):\n",
    "    # open in binary mode\n",
    "    with open(file_name, \"wb\") as file:\n",
    "        try:\n",
    "            # get request\n",
    "            response = get(url)\n",
    "            # write to file\n",
    "            file.write(response.content)\n",
    "        except:\n",
    "            print(\"fail\", file_name)\n",
    "#         print(\"wrote\", file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "url = \"http://www.scipy-lectures.org/\"\n",
    "# url = \"https://projects.iq.harvard.edu/prefresher/math\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "download_path = \"/Users/tomoyasasaki/Documents/Materials/Lectures/Scipy_lecture\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "if not os.path.exists(download_path):\n",
    "    os.makedirs(download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "soup = obtain_bs4soup(url, bypass = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preface.html\n",
      "ScipyLectures.pdf\n",
      "ScipyLectures-simple.pdf\n",
      "preface.html\n",
      "index.html\n",
      "intro.html\n",
      "python_language.html\n",
      "first_steps.html\n",
      "basic_types.html\n",
      "control_flow.html\n",
      "functions.html\n",
      "reusing_code.html\n",
      "io.html\n",
      "standard_library.html\n",
      "exceptions.html\n",
      "oop.html\n",
      "index.html\n",
      "array_object.html\n",
      "operations.html\n",
      "elaborate_arrays.html\n",
      "advanced_operations.html\n",
      "exercises.html\n",
      "gallery.html\n",
      "index.html\n",
      "scipy.html\n",
      "stats-interpolate.html\n",
      "optimize-fit.html\n",
      "image-processing.html\n",
      "answers_image_processing.html\n",
      "help.html\n",
      "index.html\n",
      "index.html\n",
      "index.html\n",
      "index.html\n",
      "index.html\n",
      "index.html\n",
      "introduction.html\n",
      "storage_schemes.html\n",
      "dia_matrix.html\n",
      "lil_matrix.html\n",
      "dok_matrix.html\n",
      "coo_matrix.html\n",
      "csr_matrix.html\n",
      "csc_matrix.html\n",
      "bsr_matrix.html\n",
      "solvers.html\n",
      "other_packages.html\n",
      "index.html\n",
      "index.html\n",
      "interfacing_with_c.html\n",
      "index.html\n",
      "index.html\n",
      "sympy.html\n",
      "index.html\n",
      "index.html\n",
      "index.html\n",
      "index.html\n",
      "ScipyLectures.pdf\n",
      "ScipyLectures-simple.pdf\n",
      "preface.html\n"
     ]
    }
   ],
   "source": [
    "## if the URL for the target file is straight forward, use this\n",
    "## e.g. <a href=\"/path/to/file.pdf\">\n",
    "\n",
    "os.chdir(download_path)\n",
    "for tag in soup.findAll('a', href = True):\n",
    "    tag2 = urllibR.urljoin(url, tag['href'])\n",
    "    if os.path.splitext(os.path.basename(tag2))[1] == \".pdf\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".ipynb\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".py\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".tex\" or\\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".zip\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".ppt\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".RData\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".html\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".R\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".txt\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".Rmd\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".md\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".r\":\n",
    "\n",
    "#     if len( os.path.splitext(os.path.basename(tag2))[1]  ) >= 1:\n",
    "        name = os.path.basename(tag2)\n",
    "#         name = os.path.basename(tag2)[:-2]\n",
    "        download(tag2, name)\n",
    "        print(name)\n",
    "        sleep(1)\n",
    "\n",
    "# end = time()\n",
    "# elapse = end - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics1_2017\n",
      "metrics2_2017\n",
      "metrics3_2017\n",
      "metrics4_2017\n",
      "metrics5_2017\n",
      "metrics6_2017\n"
     ]
    }
   ],
   "source": [
    "## if the URL for the target file is NOT straight forward, use this\n",
    "## e.g. <a href=\"path/to/file.pdf?attredirects=0&amp;d=1\">\n",
    "\n",
    "os.chdir(download_path)\n",
    "for tag in soup.findAll('a', href = True):\n",
    "    tag2 = urllibR.urljoin(url, tag['href'])\n",
    "    if \".pdf\" in os.path.splitext(os.path.basename(tag2))[1]:\n",
    "        name = os.path.splitext(os.path.basename(tag2))[0]\n",
    "        download(tag2, name + \".pdf\")\n",
    "        print(name)\n",
    "        sleep(1)\n",
    "\n",
    "# end = time()\n",
    "# elapse = end - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scratch\n",
    "\n",
    "os.chdir(download_path)\n",
    "for tag in soup.findAll('a', href = True):\n",
    "    tag2 = urllibR.urljoin(url, tag['href'])\n",
    "#     print(os.path.splitext(os.path.basename(tag['href'])) )\n",
    "#     print(tag2)\n",
    "#     if os.path.splitext(os.path.basename(tag2))[1] == \".pdf\" or os.path.splitext(os.path.basename(tag2))[1] == \".r\"\\\n",
    "    if \".xls\" in os.path.splitext(os.path.basename(tag2))[1]:\n",
    "#         print(tag2)\n",
    "#         name = os.path.basename(tag2)[:-2]\n",
    "        name = os.path.splitext(os.path.basename(tag2))[0]\n",
    "#         download(tag2, name)\n",
    "        download(tag2, name + \".xls\")\n",
    "        print(name)\n",
    "#         if name == \"sig_phrases_det.pdf\":\n",
    "#             pass\n",
    "#         else:\n",
    "#         download(tag2, re.sub(r\"\\?.+\" ,\"\",os.path.basename(tag2) ))\n",
    "#         download(url + name, name)\n",
    "#         sleep(1)\n",
    "#         tmp.append(tag2)\n",
    "\n",
    "# end = time()\n",
    "# elapse = end - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.kevinsheppard.com/This is some generic cookie text\n",
      "https://www.kevinsheppard.com/Main_Page\n",
      "https://www.kevinsheppard.com/Python_Course\n",
      "https://www.kevinsheppard.com/Category:Research\n",
      "https://www.kevinsheppard.com/Curriculum_Vita\n",
      "https://www.kevinsheppard.com/Contact\n",
      "https://www.kevinsheppard.com/Python_Course\n",
      "https://www.kevinsheppard.com/Category:MFE\n",
      "https://www.kevinsheppard.com/Category:Python\n",
      "https://www.kevinsheppard.com/Category:MATLAB\n",
      "https://www.kevinsheppard.com/Category:Lyx\n",
      "https://www.kevinsheppard.com/Category:Teaching\n",
      "https://www.kevinsheppard.com/Python_Course\n",
      "http://photos.kevinsheppard.com\n",
      "https://github.com/bashtage\n",
      "https://www.kevinsheppard.com/Python_Course#mw-navigation\n",
      "https://www.kevinsheppard.com/Python_Course#p-search\n",
      "https://www.kevinsheppard.com/Python_Course#Related_Courses\n",
      "https://www.kevinsheppard.com/Python_Course#Outline\n",
      "https://www.kevinsheppard.com/Python_Course#Notes_and_Slides\n",
      "https://www.kevinsheppard.com/Python_Course#Schedule\n",
      "https://www.kevinsheppard.com/Python_Course#YouTube_Catch-up\n",
      "https://www.kevinsheppard.com/Python_Course#Final_Exam\n",
      "https://www.kevinsheppard.com/Python_Course#Data\n",
      "https://www.kevinsheppard.com/Python_Course#IPython_Notebooks_and_Task_Solutions\n",
      "https://www.kevinsheppard.com/Python_Course#Winter_Problem_Set\n",
      "https://www.kevinsheppard.com/Python_Course#Selected_Task_Solutions\n",
      "https://www.kevinsheppard.com/Python_Course#Installation\n",
      "https://www.kevinsheppard.com/Python_Course#Subpages\n",
      "http://quant-econ.net/\n",
      "https://www.kevinsheppard.com/images/d/d2/Python_course.pdf\n",
      "https://www.kevinsheppard.com/File:Pdf_small_icon.png\n",
      "https://www.kevinsheppard.com/images/8/84/Python_course_slides.pdf\n",
      "https://www.kevinsheppard.com/File:Pdf_small_icon.png\n",
      "https://www.kevinsheppard.com/Python_for_Econometrics\n",
      "http://youtu.be/pDBb77-SfyE\n",
      "http://youtu.be/25LOe2tSmg8\n",
      "http://youtu.be/dmPaK6yXB7Q\n",
      "http://youtu.be/4smTmECyShg\n",
      "http://youtu.be/tZxkBbUj45w\n",
      "http://youtu.be/QByW3-gJplQ\n",
      "http://www.youtube.com/watch?v=TJNRtNxO-y4\n",
      "http://youtu.be/0peUjI2qWkg\n",
      "http://youtu.be/6ce0c9DkYCQ\n",
      "http://youtu.be/9BFHkVN1QsQ\n",
      "https://youtu.be/cLiXuOwDlBY\n",
      "https://youtu.be/J9inqD2xJJs\n",
      "https://www.youtube.com/watch?v=UFktWDQc868\n",
      "https://www.kevinsheppard.com/Python_Course/Final\n",
      "https://www.kevinsheppard.com/Python_Course/Data\n",
      "https://www.kevinsheppard.com/Python_Course/IPython_Notebooks\n",
      "https://www.kevinsheppard.com/Python_Course/Winter_Problem_Set\n",
      "https://www.kevinsheppard.com/images/d/de/Tasks_5.zip\n",
      "https://www.kevinsheppard.com/File:Zip_new.png\n",
      "https://www.kevinsheppard.com/images/7/7b/Tasks_6.zip\n",
      "https://www.kevinsheppard.com/File:Zip_new.png\n",
      "https://www.kevinsheppard.com/images/6/6c/Python_course_installation.pdf\n",
      "https://www.kevinsheppard.com/File:Pdf_small_icon.png\n",
      "https://www.kevinsheppard.com/Python_Course/Data\n",
      "https://www.kevinsheppard.com/Python_Course/Final\n",
      "https://www.kevinsheppard.com/Python_Course/IPython_Notebooks\n",
      "https://www.kevinsheppard.com/Python_Course/Winter_Problem_Set\n",
      "https://www.kevinsheppard.com/index.php?title=Python_Course&oldid=3650\n",
      "https://www.kevinsheppard.com/Python_Course\n",
      "https://www.kevinsheppard.com/Python_Course\n",
      "https://www.kevinsheppard.com/index.php?title=Talk:Python_Course&action=edit&redlink=1\n",
      "https://www.kevinsheppard.com/index.php?title=Python_Course&action=edit\n",
      "https://www.kevinsheppard.com/index.php?title=Python_Course&action=history\n",
      "https://www.kevinsheppard.com/Kevin_Sheppard:Privacy_policy\n",
      "https://www.kevinsheppard.com/Kevin_Sheppard:About\n",
      "https://www.kevinsheppard.com/Kevin_Sheppard:General_disclaimer\n",
      "https://www.kevinsheppard.com/index.php?title=Special:UserLogin&returnto=Python+Course\n",
      "https://creativecommons.org/licenses/by-nc-nd/4.0/\n"
     ]
    }
   ],
   "source": [
    "os.chdir(download_path)\n",
    "for tag in soup.findAll('a', href = True):\n",
    "    tag2 = urllibR.urljoin(url, tag['href'])\n",
    "    print(tag2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
