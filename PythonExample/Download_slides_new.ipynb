{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "* [here](https://null-byte.wonderhowto.com/how-to/download-all-pdfs-webpage-with-python-script-0163031/)\n",
    "* [here](https://stackoverflow.com/questions/7243750/download-file-from-web-in-python-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse as urllib\n",
    "import urllib3\n",
    "import os\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as urllibR\n",
    "from requests import get\n",
    "from time import sleep, time\n",
    "import re\n",
    "from random import randint\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function to download (bypass using firefox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "def obtain_bs4soup(url, bypass):\n",
    "    try:\n",
    "        os.mkdir(download_path)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0\",\n",
    "    }\n",
    "    \n",
    "    ## Choose whether to bypass through firefox\n",
    "    if bypass == True:\n",
    "        request0 = urllibR.Request(url=url, headers=headers)\n",
    "        request = urllibR.urlopen(request0)\n",
    "    else:\n",
    "        request = urllibR.urlopen(url)\n",
    "        \n",
    "    soup = BeautifulSoup(request.read(), \"lxml\")\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "def download(url, file_name):\n",
    "    # open in binary mode\n",
    "    with open(file_name, \"wb\") as file:\n",
    "        try:\n",
    "            # get request\n",
    "            response = get(url)\n",
    "            # write to file\n",
    "            file.write(response.content)\n",
    "        except:\n",
    "            print(\"fail\", file_name)\n",
    "#         print(\"wrote\", file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## if you get the following error, use this. \n",
    "## There is some problem in the SSL \n",
    "## <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed ... >\n",
    "## https://stackoverflow.com/questions/27835619/urllib-and-ssl-certificate-verify-failed-error\n",
    "## https://shinespark.hatenablog.com/entry/2015/12/06/100000\n",
    "import ssl\n",
    "\n",
    "# This restores the same behavior as before.\n",
    "context = ssl._create_unverified_context()\n",
    "urllib.urlopen(\"https://no-valid-cert\", context=context)\n",
    "\n",
    "# more discouraged options\n",
    "# ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "# download_path = \"/Users/tomoyasasaki/GoogleDrive/CurrentLecture/POL574/\"\n",
    "# download_path = \"/Users/tomoyasasaki/Documents/Materials/Math466or566_Arizona_Kennedy\"\n",
    "# download_path = \"/Users/tomoyasasaki/Documents/MIT_class/Past/18175_theory_statistics\"\n",
    "download_path = \"/Users/tomoyasasaki/Downloads/10shinto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "if not os.path.exists(download_path):\n",
    "    os.makedirs(download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "url = \"http://blog.livedoor.jp/kinisoku/archives/4950402.html\"\n",
    "# url = \"https://projects.iq.harvard.edu/prefresher/math\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "soup = obtain_bs4soup(url, bypass = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78b967de.jpg\n",
      "dac31356.jpg\n",
      "99e50e71.jpg\n",
      "1ad136d2.png\n",
      "2552b07b.png\n",
      "fe61ff55.jpg\n",
      "b8f09276.jpg\n",
      "a657f758.jpg\n",
      "65f474d3.jpg\n",
      "40e0330f.jpg\n",
      "e80ec7ac.jpg\n",
      "7bdeb0f2.jpg\n",
      "087cebdd.jpg\n",
      "8efec27e.jpg\n",
      "16ce81e3.jpg\n",
      "7ecbdbfc.jpg\n",
      "00bef84e.jpg\n",
      "001b120f.jpg\n",
      "11017e4d.jpg\n",
      "41bae0f4.jpg\n",
      "663583b2.jpg\n",
      "ec7bf3c5.jpg\n",
      "fa071375.jpg\n",
      "d79f5613.jpg\n",
      "5d278876.jpg\n",
      "ff4e9d67.jpg\n",
      "67ae2d60.jpg\n",
      "2716277c.jpg\n",
      "5d510518.jpg\n",
      "dc600cfb.jpg\n",
      "9b24c50e.jpg\n",
      "cd815468.jpg\n",
      "190efa8f.jpg\n",
      "a45f3749.jpg\n",
      "f22816b9.jpg\n",
      "ab98526b.jpg\n",
      "c905ac2d.jpg\n",
      "53a7e093.jpg\n",
      "82ab8de5.jpg\n",
      "3458df8e.png\n",
      "c33e41f6.jpg\n",
      "c163680b.jpg\n",
      "7203a0b5.png\n",
      "3d141fa1.jpg\n",
      "88fb27a3.jpg\n",
      "f08f4571.jpg\n",
      "9c25202f.jpg\n",
      "9d87055a.jpg\n",
      "de9ad01c.jpg\n",
      "b39f5c37.jpg\n",
      "c352ed52.jpg\n",
      "e1a96b4a.jpg\n",
      "\n",
      " END\n"
     ]
    }
   ],
   "source": [
    "## if the URL for the target file is straight forward, use this\n",
    "## e.g. <a href=\"/path/to/file.pdf\">\n",
    "\n",
    "os.chdir(download_path)\n",
    "for tag in soup.findAll('a', href = True):\n",
    "    tag2 = urllibR.urljoin(url, tag['href'])\n",
    "#     if os.path.splitext(os.path.basename(tag2))[1] == \".pdf\" or \\\n",
    "#     os.path.splitext(os.path.basename(tag2))[1] == \".ipynb\" or \\\n",
    "#     os.path.splitext(os.path.basename(tag2))[1] == \".py\" or \\\n",
    "#     os.path.splitext(os.path.basename(tag2))[1] == \".tex\" or\\\n",
    "#     os.path.splitext(os.path.basename(tag2))[1] == \".zip\" or \\\n",
    "#     os.path.splitext(os.path.basename(tag2))[1] == \".ppt\" or \\\n",
    "#     os.path.splitext(os.path.basename(tag2))[1] == \".RData\" or \\\n",
    "#     os.path.splitext(os.path.basename(tag2))[1] == \".html\" or \\\n",
    "#     os.path.splitext(os.path.basename(tag2))[1] == \".R\" or \\\n",
    "#     os.path.splitext(os.path.basename(tag2))[1] == \".txt\" or \\\n",
    "#     os.path.splitext(os.path.basename(tag2))[1] == \".Rmd\" or \\\n",
    "#     os.path.splitext(os.path.basename(tag2))[1] == \".md\" or \\\n",
    "#     os.path.splitext(os.path.basename(tag2))[1] == \".r\" or\\\n",
    "#     os.path.splitext(os.path.basename(tag2))[1] == \".csv\":\n",
    "    if os.path.splitext(os.path.basename(tag2))[1] == \".jpg\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".png\":\n",
    "\n",
    "#     if len( os.path.splitext(os.path.basename(tag2))[1]  ) >= 1:\n",
    "        name = os.path.basename(tag2)\n",
    "#         name = os.path.basename(tag2)[:-2]\n",
    "        download(tag2, name)\n",
    "        print(name)\n",
    "        sleep(2)\n",
    "\n",
    "print(\"\\n END\")\n",
    "# end = time()\n",
    "# elapse = end - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "owen_-_1\n",
      "owen_-_2\n",
      "owen_-_3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-250552d4e994>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# end = time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## if the URL for the target file is NOT straight forward, use this\n",
    "## e.g. <a href=\"path/to/file.pdf?attredirects=0&amp;d=1\">\n",
    "\n",
    "os.chdir(download_path)\n",
    "for tag in soup.findAll('a', href = True):\n",
    "    tag2 = urllibR.urljoin(url, tag['href'])\n",
    "    if \".pdf\" in os.path.splitext(os.path.basename(tag2))[1]:\n",
    "        name = os.path.splitext(os.path.basename(tag2))[0]\n",
    "        download(tag2, name + \".pdf\")\n",
    "        print(name)\n",
    "        sleep(1)\n",
    "\n",
    "# end = time()\n",
    "# elapse = end - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scratch\n",
    "\n",
    "os.chdir(download_path)\n",
    "for tag in soup.findAll('a', href = True):\n",
    "    tag2 = urllibR.urljoin(url, tag['href'])\n",
    "#     print(os.path.splitext(os.path.basename(tag['href'])) )\n",
    "#     print(tag2)\n",
    "#     if os.path.splitext(os.path.basename(tag2))[1] == \".pdf\" or os.path.splitext(os.path.basename(tag2))[1] == \".r\"\\\n",
    "    if \".xls\" in os.path.splitext(os.path.basename(tag2))[1]:\n",
    "#         print(tag2)\n",
    "#         name = os.path.basename(tag2)[:-2]\n",
    "        name = os.path.splitext(os.path.basename(tag2))[0]\n",
    "#         download(tag2, name)\n",
    "        download(tag2, name + \".xls\")\n",
    "        print(name)\n",
    "#         if name == \"sig_phrases_det.pdf\":\n",
    "#             pass\n",
    "#         else:\n",
    "#         download(tag2, re.sub(r\"\\?.+\" ,\"\",os.path.basename(tag2) ))\n",
    "#         download(url + name, name)\n",
    "#         sleep(1)\n",
    "#         tmp.append(tag2)\n",
    "\n",
    "# end = time()\n",
    "# elapse = end - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://blackboard.princeton.edu/webapps/login/?new_loc=%2Fwebapps%2Fblackboard%2Fcontent%2FlistContent.jsp%3Fcourse_id%3D_6116604_1%26content_id%3D_2189650_1%26mode%3Dreset\n"
     ]
    }
   ],
   "source": [
    "# os.chdir(download_path)\n",
    "for tag in soup.findAll('a', href = True):\n",
    "    tag2 = urllibR.urljoin(url, tag['href'])\n",
    "    print(tag2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html dir=\"ltr\"><head>\n",
       "<meta content=\"no-cache\" http-equiv=\"Pragma\"/><meta content=\"no-cache\" http-equiv=\"Cache-Control\"/>\n",
       "<script language=\"Javascript\">\n",
       "  cookie_name = \"cookies_enabled\";\n",
       "  document.cookie=cookie_name+\"=yes\";\n",
       "  if (!document.cookie) {\n",
       "    document.location.href=\"/webapps/login/nocookies.jsp\";\n",
       "  }\n",
       "  document.cookie=cookie_name+\"yes;expires=Thu, 01-Jan-1970 00:00:01 GMT\";\n",
       "</script>\n",
       "<script language=\"Javascript\"><!--\n",
       "document.location.replace('https://blackboard.princeton.edu/webapps/login/?new_loc=%2Fwebapps%2Fblackboard%2Fcontent%2FlistContent.jsp%3Fcourse_id%3D_6116604_1%26content_id%3D_2189650_1%26mode%3Dreset');\n",
       "//--></script></head>\n",
       "<body alink=\"#000000\" bgcolor=\"#FFFFFF\" link=\"#000000\">\n",
       "<br/><br/><br/><br/><div style=\"text-align: center;\"><hr height=\"5\" width=\"350\"/><br/>\n",
       "<strong>You are being redirected to another page</strong>\n",
       "<p><strong>Please Wait...</strong><br/><br/></p><hr height=\"5\" width=\"350\"/>\n",
       "<br/><a href=\"https://blackboard.princeton.edu/webapps/login/?new_loc=%2Fwebapps%2Fblackboard%2Fcontent%2FlistContent.jsp%3Fcourse_id%3D_6116604_1%26content_id%3D_2189650_1%26mode%3Dreset\"><strong>Click here to access the page to which you are being forwarded.</strong></a></div>\n",
       "</body></html>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# soup.findAll('a', href = True)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"/Users/tomoyasasaki/Documents/Materials/Books_files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tomoyasasaki/Documents/Materials/Books_files/yeonkim'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "old_name = os.path.basename(item)\n",
    "if old_name[0].islower( ) == True:\n",
    "    print(\"1\")\n",
    "    new_name = old_name[0].upper() + old_name[1:]\n",
    "    print(\"2\")\n",
    "    os.rename(old_name, new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\">\n",
       "<html>\n",
       "<head>\n",
       "<meta content=\"IBM WebSphere Studio Homepage Builder Version 13.0.4.0 for Windows\" name=\"GENERATOR\"/>\n",
       "<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
       "<meta content=\"text/css\" http-equiv=\"Content-Style-Type\"/>\n",
       "<title>Econometrics II '10</title>\n",
       "</head>\n",
       "<body>\n",
       "<p><font size=\"+3\"></font></p></body></html>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
