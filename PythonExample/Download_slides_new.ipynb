{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "* [here](https://null-byte.wonderhowto.com/how-to/download-all-pdfs-webpage-with-python-script-0163031/)\n",
    "* [here](https://stackoverflow.com/questions/7243750/download-file-from-web-in-python-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse as urllib\n",
    "import urllib3\n",
    "import os\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as urllibR\n",
    "from requests import get\n",
    "from time import sleep, time\n",
    "import re\n",
    "from random import randint\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function to download (bypass using firefox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "def obtain_bs4soup(url, bypass):\n",
    "    try:\n",
    "        os.mkdir(download_path)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0\",\n",
    "    }\n",
    "    \n",
    "    ## Choose whether to bypass through firefox\n",
    "    if bypass == True:\n",
    "        request0 = urllibR.Request(url=url, headers=headers)\n",
    "        request = urllibR.urlopen(request0)\n",
    "    else:\n",
    "        request = urllibR.urlopen(url)\n",
    "        \n",
    "    soup = BeautifulSoup(request.read(), \"lxml\")\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "def download(url, file_name):\n",
    "    # open in binary mode\n",
    "    with open(file_name, \"wb\") as file:\n",
    "        try:\n",
    "            # get request\n",
    "            response = get(url)\n",
    "            # write to file\n",
    "            file.write(response.content)\n",
    "        except:\n",
    "            print(\"fail\", file_name)\n",
    "#         print(\"wrote\", file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "## if you get the following error, use this. \n",
    "## There is some problem in the SSL \n",
    "## <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed ... >\n",
    "## https://stackoverflow.com/questions/27835619/urllib-and-ssl-certificate-verify-failed-error\n",
    "## https://shinespark.hatenablog.com/entry/2015/12/06/100000\n",
    "\n",
    "import ssl\n",
    "\n",
    "# This restores the same behavior as before.\n",
    "# context = ssl._create_unverified_context()\n",
    "# urlopen(\"https://no-valid-cert\", context=context)\n",
    "\n",
    "# more discouraged options\n",
    "# ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "# download_path = \"/Users/tomoyasasaki/GoogleDrive/CurrentLecture/POL574/\"\n",
    "# download_path = \"/Users/tomoyasasaki/Documents/Materials/LectureNotesEconometrics/econ583_econometrics_wustl\"\n",
    "# download_path = \"/Users/tomoyasasaki/Documents/Materials/LectureNotes/2019SICSS\"\n",
    "download_path = \"/Users/tomoyasasaki/Documents/Materials/LectureNotesMath/Ishikawa_mondoshu\"\n",
    "# download_path = \"/Users/tomoyasasaki/Documents/MIT_class/Past/18.408_Algorithm_ML_2017\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "if not os.path.exists(download_path):\n",
    "    os.makedirs(download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 3\n",
    "# url = \"http://web.hku.hk/~pingyu/6005/6005.htm\"\n",
    "url = \"http://www.math.sci.hokudai.ac.jp/~ishikawa/mondou.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "soup = obtain_bs4soup(url, bypass = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index.html\n",
      "daisekai.html\n",
      "lecture.html\n",
      "nyuumon1.pdf\n",
      "nyuumon3.pdf\n",
      "nyuumon4.pdf\n",
      "nyuumon6.pdf\n",
      "nyuumon8.pdf\n",
      "nyuumontok.pdf\n",
      "tabi1.pdf\n",
      "tabi2.pdf\n",
      "tabi3.pdf\n",
      "tabi4.pdf\n",
      "tabi5.pdf\n",
      "tabi6new.pdf\n",
      "tabi7.pdf\n",
      "tabi8.pdf\n",
      "tabi9.pdf\n",
      "tabi10.pdf\n",
      "kika.pdf\n",
      "linear1.pdf\n",
      "linear2.pdf\n",
      "linear3new.pdf\n",
      "linear4new.pdf\n",
      "linear5.pdf\n",
      "linear6.pdf\n",
      "linear7.pdf\n",
      "linear8.pdf\n",
      "linear9.pdf\n",
      "linear10.pdf\n",
      "linear11.pdf\n",
      "yasenkei1.pdf\n",
      "yasenkei3.pdf\n",
      "yasenkei5.pdf\n",
      "yasenkei7.pdf\n",
      "yasenkei9.pdf\n",
      "yasenkei11.pdf\n",
      "senkei05-1.pdf\n",
      "senkei05-2.pdf\n",
      "senkei05-3.pdf\n",
      "senkei05-2-1.pdf\n",
      "senkei05-2-2.pdf\n",
      "senkei05-2-3.pdf\n",
      "calculus1.pdf\n",
      "calculus2.pdf\n",
      "calculus3.pdf\n",
      "calculus4.pdf\n",
      "calculus5.pdf\n",
      "calculus6.pdf\n",
      "calculus7.pdf\n",
      "calculus8.pdf\n",
      "calculus9.pdf\n",
      "bibun04bun1.pdf\n",
      "bibun04bun2.pdf\n",
      "bibun04bun3.pdf\n",
      "bibun04bun4.pdf\n",
      "bibun04nou1.pdf\n",
      "bibun04nou2.pdf\n",
      "bibun04nou3.pdf\n",
      "bibun04nou4.pdf\n",
      "bibun04nou5.pdf\n",
      "love1.pdf\n",
      "love2.pdf\n",
      "love3.pdf\n",
      "love4.pdf\n",
      "love5.pdf\n",
      "love6.pdf\n",
      "love7.pdf\n",
      "TOP05-1.PDF\n",
      "TOP05-2.PDF\n",
      "diffeq1.pdf\n",
      "diffeq2.pdf\n",
      "diffeq3.pdf\n",
      "diffeq4.pdf\n",
      "diffeq5.pdf\n",
      "diffeq6.pdf\n",
      "diffeq7.pdf\n",
      "diffeq8.pdf\n",
      "vector1.pdf\n",
      "vector2.pdf\n",
      "vector3.pdf\n",
      "vector4.pdf\n",
      "vector5.pdf\n",
      "vector6.pdf\n",
      "vector7.pdf\n",
      "vector8.pdf\n",
      "vector9.pdf\n",
      "vector10.pdf\n",
      "Ekaitou1.pdf\n",
      "Ekaitou2.pdf\n",
      "Ekaitou3.pdf\n",
      "topology1.pdf\n",
      "topology2.pdf\n",
      "topology3.pdf\n",
      "topology4.pdf\n",
      "topology5.pdf\n",
      "topology6.pdf\n",
      "topology7.pdf\n",
      "topology8.pdf\n",
      "topology9.pdf\n",
      "topology10.pdf\n",
      "topology11.pdf\n",
      "kyokumen1.pdf\n",
      "kyokumen2.pdf\n",
      "kyokumen3.pdf\n",
      "kyokumen4.pdf\n",
      "kyokumen5.pdf\n",
      "kyokumen6.pdf\n",
      "kyokumen7.pdf\n",
      "kyokumen8.pdf\n",
      "kyokumen9.pdf\n",
      "isoukika1.pdf\n",
      "isoukika3.pdf\n",
      "isoukika5.pdf\n",
      "isoukika7.pdf\n",
      "isoukika9.pdf\n",
      "manifold1.pdf\n",
      "manifold2.pdf\n",
      "manifold3.pdf\n",
      "manifold4.pdf\n",
      "manifold5.pdf\n",
      "manifold6.pdf\n",
      "manifold7.pdf\n",
      "manifold8.pdf\n",
      "manifold9.pdf\n",
      "manifold10.pdf\n",
      "manifold11.pdf\n",
      "difftop1.pdf\n",
      "difftop2.pdf\n",
      "difftop3.pdf\n",
      "difftop5.pdf\n",
      "difftop7.pdf\n",
      "difftop8.pdf\n",
      "difftop9.pdf\n",
      "difftop10.pdf\n",
      "difftop11.pdf\n",
      "difftop12.pdf\n",
      "tokuiten.pdf\n",
      "gauss1.pdf\n",
      "gauss2.pdf\n",
      "gauss3.pdf\n",
      "gauss4.pdf\n",
      "gauss5.pdf\n",
      "gauss6.pdf\n",
      "gauss7.pdf\n",
      "gauss8.pdf\n",
      "gauss9.pdf\n",
      "mapqans1.pdf\n",
      "mapqans2.pdf\n",
      "index.html\n",
      "lecture.html\n",
      "\n",
      " END\n"
     ]
    }
   ],
   "source": [
    "## if the URL for the target file is straight forward, use this\n",
    "## e.g. <a href=\"/path/to/file.pdf\">\n",
    "\n",
    "os.chdir(download_path)\n",
    "for tag in soup.findAll('a', href = True):\n",
    "    tag2 = urllibR.urljoin(url, tag['href'])\n",
    "    if os.path.splitext(os.path.basename(tag2))[1] == \".pdf\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".ipynb\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".py\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".tex\" or\\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".zip\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".ppt\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".RData\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".html\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".R\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".txt\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".Rmd\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".md\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".r\" or\\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".csv\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".PDF\":\n",
    "#     if os.path.splitext(os.path.basename(tag2))[1] == \".jpg\" or \\\n",
    "#     os.path.splitext(os.path.basename(tag2))[1] == \".png\":\n",
    "\n",
    "#     if len( os.path.splitext(os.path.basename(tag2))[1]  ) >= 1:\n",
    "        name = os.path.basename(tag2)\n",
    "#         name = os.path.basename(tag2)[:-2]\n",
    "        download(tag2, name)\n",
    "        print(name)\n",
    "        sleep(2)\n",
    "\n",
    "print(\"\\n END\")\n",
    "# end = time()\n",
    "# elapse = end - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://eml.berkeley.edu/~mcfadden/e240b_sp03/e240b.html'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if the URL for the target file is NOT straight forward, use this\n",
    "## e.g. <a href=\"path/to/file.pdf?attredirects=0&amp;d=1\">\n",
    "\n",
    "os.chdir(download_path)\n",
    "for tag in soup.findAll('a', href = True):\n",
    "    tag2 = urllibR.urljoin(url, tag['href'])\n",
    "    if \".pdf\" in os.path.splitext(os.path.basename(tag2))[1]:\n",
    "        name = os.path.splitext(os.path.basename(tag2))[0]\n",
    "        download(tag2, name + \".pdf\")\n",
    "        print(name)\n",
    "        sleep(1)\n",
    "\n",
    "# end = time()\n",
    "# elapse = end - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scratch\n",
    "\n",
    "os.chdir(download_path)\n",
    "for tag in soup.findAll('a', href = True):\n",
    "    tag2 = urllibR.urljoin(url, tag['href'])\n",
    "#     print(os.path.splitext(os.path.basename(tag['href'])) )\n",
    "#     print(tag2)\n",
    "#     if os.path.splitext(os.path.basename(tag2))[1] == \".pdf\" or os.path.splitext(os.path.basename(tag2))[1] == \".r\"\\\n",
    "    if \".xls\" in os.path.splitext(os.path.basename(tag2))[1]:\n",
    "#         print(tag2)\n",
    "#         name = os.path.basename(tag2)[:-2]\n",
    "        name = os.path.splitext(os.path.basename(tag2))[0]\n",
    "#         download(tag2, name)\n",
    "        download(tag2, name + \".xls\")\n",
    "        print(name)\n",
    "#         if name == \"sig_phrases_det.pdf\":\n",
    "#             pass\n",
    "#         else:\n",
    "#         download(tag2, re.sub(r\"\\?.+\" ,\"\",os.path.basename(tag2) ))\n",
    "#         download(url + name, name)\n",
    "#         sleep(1)\n",
    "#         tmp.append(tag2)\n",
    "\n",
    "# end = time()\n",
    "# elapse = end - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://blackboard.princeton.edu/webapps/login/?new_loc=%2Fwebapps%2Fblackboard%2Fcontent%2FlistContent.jsp%3Fcourse_id%3D_6116604_1%26content_id%3D_2189650_1%26mode%3Dreset\n"
     ]
    }
   ],
   "source": [
    "# os.chdir(download_path)\n",
    "for tag in soup.findAll('a', href = True):\n",
    "    tag2 = urllibR.urljoin(url, tag['href'])\n",
    "    print(tag2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tomoyasasaki/Documents/Materials/Books_files/yeonkim'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "old_name = os.path.basename(item)\n",
    "if old_name[0].islower( ) == True:\n",
    "    print(\"1\")\n",
    "    new_name = old_name[0].upper() + old_name[1:]\n",
    "    print(\"2\")\n",
    "    os.rename(old_name, new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
